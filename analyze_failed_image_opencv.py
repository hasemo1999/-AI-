import cv2
import numpy as np
import os

def analyze_image_details(image_path):
    """ç”»åƒã®è©³ç´°åˆ†æ"""
    print(f"=== ç”»åƒè©³ç´°åˆ†æ: {os.path.basename(image_path)} ===")
    
    # ç”»åƒã‚’èª­ã¿è¾¼ã¿
    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    
    if image is None:
        print("âŒ ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—")
        return
    
    # åŸºæœ¬æƒ…å ±
    h, w = image.shape[:2]
    print(f"ç”»åƒã‚µã‚¤ã‚º: {w} x {h}")
    print(f"ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”: {w/h:.2f}")
    
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # ç”»åƒã®çµ±è¨ˆæƒ…å ±
    mean_brightness = np.mean(gray)
    std_brightness = np.std(gray)
    min_brightness = np.min(gray)
    max_brightness = np.max(gray)
    
    print(f"å¹³å‡è¼åº¦: {mean_brightness:.1f}")
    print(f"è¼åº¦æ¨™æº–åå·®: {std_brightness:.1f}")
    print(f"æœ€å°è¼åº¦: {min_brightness}")
    print(f"æœ€å¤§è¼åº¦: {max_brightness}")
    print(f"ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ: {max_brightness - min_brightness}")
    
    # ã‚¨ãƒƒã‚¸æ¤œå‡º
    edges = cv2.Canny(gray, 50, 150)
    edge_density = np.sum(edges > 0) / (w * h)
    print(f"ã‚¨ãƒƒã‚¸å¯†åº¦: {edge_density:.4f}")
    
    # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«æ¨å®š
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    noise = cv2.absdiff(gray, blurred)
    noise_level = np.mean(noise)
    print(f"æ¨å®šãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {noise_level:.1f}")
    
    # ç”»åƒã®å“è³ªè©•ä¾¡
    if mean_brightness < 50:
        print("âš ï¸ ç”»åƒãŒæš—ã™ãã¾ã™")
    elif mean_brightness > 200:
        print("âš ï¸ ç”»åƒãŒæ˜ã‚‹ã™ãã¾ã™")
    
    if std_brightness < 20:
        print("âš ï¸ ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãŒä½ã™ãã¾ã™")
    
    if edge_density < 0.01:
        print("âš ï¸ ã‚¨ãƒƒã‚¸ãŒå°‘ãªã™ãã¾ã™ï¼ˆã¼ã‚„ã‘ã¦ã„ã‚‹å¯èƒ½æ€§ï¼‰")
    
    if noise_level > 10:
        print("âš ï¸ ãƒã‚¤ã‚ºãŒå¤šã™ãã¾ã™")
    
    return {
        'size': (w, h),
        'brightness': mean_brightness,
        'contrast': max_brightness - min_brightness,
        'edge_density': edge_density,
        'noise_level': noise_level
    }

def test_extreme_preprocessing(image_path):
    """æ¥µç«¯ãªå‰å‡¦ç†ã‚’è©¦è¡Œ"""
    print(f"\n=== æ¥µç«¯å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ: {os.path.basename(image_path)} ===")
    
    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # æ¥µç«¯ãªå‰å‡¦ç†æ‰‹æ³•
    extreme_methods = [
        ("æ¥µç«¯CLAHE", lambda img: cv2.createCLAHE(clipLimit=10.0, tileGridSize=(4,4)).apply(img)),
        ("æ¥µç«¯ã‚¬ã‚¦ã‚·ã‚¢ãƒ³", lambda img: cv2.GaussianBlur(img, (15,15), 0)),
        ("æ¥µç«¯ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³", lambda img: cv2.medianBlur(img, 15)),
        ("æ¥µç«¯ãƒã‚¤ãƒ©ãƒ†ãƒ©ãƒ«", lambda img: cv2.bilateralFilter(img, 15, 75, 75)),
        ("æ¥µç«¯ãƒã‚¤ã‚ºé™¤å»", lambda img: cv2.fastNlMeansDenoising(img, None, 30, 7, 21)),
        ("æ¥µç«¯ã‚¨ãƒƒã‚¸å¼·èª¿", lambda img: cv2.filter2D(img, -1, np.array([[-2,-2,-2], [-2,17,-2], [-2,-2,-2]]))),
        ("æ¥µç«¯ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–é–¾å€¤", lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 21, 5)),
        ("æ¥µç«¯Otsué–¾å€¤", lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]),
        ("ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼å‡¦ç†", lambda img: cv2.morphologyEx(img, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))),
        ("æ¥µç«¯ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—", lambda img: cv2.resize(img, (img.shape[1]*4, img.shape[0]*4), interpolation=cv2.INTER_CUBIC)),
    ]
    
    qr_detector = cv2.QRCodeDetector()
    
    for method_name, process_func in extreme_methods:
        try:
            processed = process_func(gray)
            
            # OpenCV
            data, bbox, straight_qrcode = qr_detector.detectAndDecode(processed)
            if data:
                print(f"âœ… {method_name}: OpenCVã§æˆåŠŸ")
                return data, f"æ¥µç«¯{method_name}+OpenCV"
                
        except Exception as e:
            print(f"âŒ {method_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
            continue
    
    print("âŒ å…¨ã¦ã®æ¥µç«¯å‰å‡¦ç†ã§å¤±æ•—")
    return None, "æ¥µç«¯å‰å‡¦ç†å¤±æ•—"

def test_region_extraction(image_path):
    """ç”»åƒã®ç‰¹å®šé ˜åŸŸã‚’æŠ½å‡ºã—ã¦ãƒ†ã‚¹ãƒˆ"""
    print(f"\n=== é ˜åŸŸæŠ½å‡ºãƒ†ã‚¹ãƒˆ: {os.path.basename(image_path)} ===")
    
    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    h, w = image.shape[:2]
    
    # ç”»åƒã‚’9åˆ†å‰²ã—ã¦å„é ˜åŸŸã‚’ãƒ†ã‚¹ãƒˆ
    regions = [
        ("å·¦ä¸Š", (0, 0, w//3, h//3)),
        ("ä¸­å¤®ä¸Š", (w//3, 0, 2*w//3, h//3)),
        ("å³ä¸Š", (2*w//3, 0, w, h//3)),
        ("å·¦ä¸­å¤®", (0, h//3, w//3, 2*h//3)),
        ("ä¸­å¤®", (w//3, h//3, 2*w//3, 2*h//3)),
        ("å³ä¸­å¤®", (2*w//3, h//3, w, 2*h//3)),
        ("å·¦ä¸‹", (0, 2*h//3, w//3, h)),
        ("ä¸­å¤®ä¸‹", (w//3, 2*h//3, 2*w//3, h)),
        ("å³ä¸‹", (2*w//3, 2*h//3, w, h))
    ]
    
    qr_detector = cv2.QRCodeDetector()
    
    for region_name, (x1, y1, x2, y2) in regions:
        try:
            # é ˜åŸŸã‚’æŠ½å‡º
            roi = image[y1:y2, x1:x2]
            
            # OpenCV
            data, bbox, straight_qrcode = qr_detector.detectAndDecode(roi)
            if data:
                print(f"âœ… {region_name}é ˜åŸŸ: OpenCVã§æˆåŠŸ")
                return data, f"{region_name}é ˜åŸŸ+OpenCV"
                
        except Exception as e:
            print(f"âŒ {region_name}é ˜åŸŸ: ã‚¨ãƒ©ãƒ¼ - {e}")
            continue
    
    print("âŒ å…¨ã¦ã®é ˜åŸŸã§å¤±æ•—")
    return None, "é ˜åŸŸæŠ½å‡ºå¤±æ•—"

def test_rotation_angles(image_path):
    """å›è»¢è§’åº¦ã‚’å¤‰ãˆã¦ãƒ†ã‚¹ãƒˆ"""
    print(f"\n=== å›è»¢ãƒ†ã‚¹ãƒˆ: {os.path.basename(image_path)} ===")
    
    image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    h, w = image.shape[:2]
    
    # å›è»¢ä¸­å¿ƒ
    center = (w // 2, h // 2)
    
    # å›è»¢è§’åº¦
    angles = [90, 180, 270, -90, -180, -270]
    
    qr_detector = cv2.QRCodeDetector()
    
    for angle in angles:
        try:
            # å›è»¢è¡Œåˆ—
            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            
            # å›è»¢å¾Œã®ç”»åƒã‚µã‚¤ã‚ºã‚’è¨ˆç®—
            cos_val = abs(rotation_matrix[0, 0])
            sin_val = abs(rotation_matrix[0, 1])
            new_w = int((h * sin_val) + (w * cos_val))
            new_h = int((h * cos_val) + (w * sin_val))
            
            # å¹³è¡Œç§»å‹•ã‚’èª¿æ•´
            rotation_matrix[0, 2] += (new_w / 2) - center[0]
            rotation_matrix[1, 2] += (new_h / 2) - center[1]
            
            # å›è»¢å®Ÿè¡Œ
            rotated = cv2.warpAffine(image, rotation_matrix, (new_w, new_h))
            
            # QRã‚³ãƒ¼ãƒ‰æ¤œå‡º
            data, bbox, straight_qrcode = qr_detector.detectAndDecode(rotated)
            if data:
                print(f"âœ… å›è»¢{angle}åº¦: OpenCVã§æˆåŠŸ")
                return data, f"å›è»¢{angle}åº¦+OpenCV"
                
        except Exception as e:
            print(f"âŒ å›è»¢{angle}åº¦: ã‚¨ãƒ©ãƒ¼ - {e}")
            continue
    
    print("âŒ å…¨ã¦ã®å›è»¢ã§å¤±æ•—")
    return None, "å›è»¢å¤±æ•—"

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    image_path = r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\INBOX\IMG_7010.JPG"
    
    if not os.path.exists(image_path):
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return
    
    # 1. ç”»åƒè©³ç´°åˆ†æ
    analysis = analyze_image_details(image_path)
    
    # 2. æ¥µç«¯å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ
    qr_data, status = test_extreme_preprocessing(image_path)
    
    if qr_data:
        print(f"\nğŸ‰ æ¥µç«¯å‰å‡¦ç†ã§æˆåŠŸï¼")
        print(f"æ‰‹æ³•: {status}")
        print(f"ãƒ‡ãƒ¼ã‚¿: {qr_data}")
        return
    
    # 3. é ˜åŸŸæŠ½å‡ºãƒ†ã‚¹ãƒˆ
    qr_data, status = test_region_extraction(image_path)
    
    if qr_data:
        print(f"\nğŸ‰ é ˜åŸŸæŠ½å‡ºã§æˆåŠŸï¼")
        print(f"æ‰‹æ³•: {status}")
        print(f"ãƒ‡ãƒ¼ã‚¿: {qr_data}")
        return
    
    # 4. å›è»¢ãƒ†ã‚¹ãƒˆ
    qr_data, status = test_rotation_angles(image_path)
    
    if qr_data:
        print(f"\nğŸ‰ å›è»¢ã§æˆåŠŸï¼")
        print(f"æ‰‹æ³•: {status}")
        print(f"ãƒ‡ãƒ¼ã‚¿: {qr_data}")
        return
    
    print(f"\nâŒ å…¨ã¦ã®æ‰‹æ³•ã§å¤±æ•—")
    print("ã“ã®ç”»åƒã«ã¯QRã‚³ãƒ¼ãƒ‰ãŒå­˜åœ¨ã—ãªã„ã‹ã€æ¤œå‡ºä¸å¯èƒ½ãªçŠ¶æ…‹ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    print("IMG_7010.JPGã«ã¯å®Ÿéš›ã«QRã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚")

if __name__ == '__main__':
    main()
